# ğŸ” RAG Pipeline â€“ LangGraph + Streamlit

This project implements a **Retrieval-Augmented Generation (RAG) pipeline** using **LangGraph** for orchestration and **Streamlit** for an interactive user interface.  
It demonstrates how document retrieval and language model generation can be combined using a **graph-based execution flow** instead of linear chains.

The goal of this project is to show how **LangGraph can be used to structure, control, and reason about RAG workflows** in a clear and extensible way.

---

## ğŸ¯ Purpose

- Demonstrate a **from-scratch RAG pipeline**
- Use **LangGraph** to explicitly model retrieval and generation steps
- Show how graph-based orchestration improves clarity and control
- Provide both **CLI-based execution** and an **interactive UI**
- Serve as a foundation for more advanced agentic RAG systems

---

## âœ¨ Key Features

- ğŸ” Document retrieval using vector similarity search  
- ğŸ§  Language model generation grounded in retrieved context  
- ğŸ”— Graph-based orchestration using LangGraph  
- ğŸ›ï¸ Explicit control over pipeline execution flow  
- ğŸ¨ Optional Streamlit UI for interactive querying  
- ğŸ§ª Clear separation of retrieval and generation logic  

---

## ğŸ§  How the Pipeline Works

1. Knowledge base is loaded into the system  
2. Text is split into semantic chunks  
3. Chunks are converted into embeddings  
4. Embeddings are stored in a vector store  
5. A user query triggers the LangGraph workflow  
6. Relevant chunks are retrieved via similarity search  
7. Retrieved context is passed to the LLM  
8. The LLM generates a grounded response  

This design ensures responses are **context-aware, traceable, and extensible**.

---

## ğŸ§© Architecture Diagram

User  
â†“  
Query Input (CLI or Streamlit UI)  
â†“  
LangGraph Workflow  
â†’ Retrieve Node (Vector Store Search)  
â†’ Generate Node (LLM with Retrieved Context)  
â†“  
Final Answer Returned to User  

---

## ğŸ—‚ï¸ Project Structure

04_langgraph_rag_chatbot/  
â”œâ”€â”€ rag_pipeline_from_scratch.py     â€“ Standalone RAG pipeline (no UI)  
â”œâ”€â”€ rag_pipeline_streamlit.py        â€“ Streamlit-based interactive UI  
â”œâ”€â”€ knowledge_base/                  â€“ Source documents / text files  
â”œâ”€â”€ requirements.txt                 â€“ Python dependencies  
â””â”€â”€ README.md                        â€“ Project documentation  

---

## ğŸš€ How to Run the Project

Run the backend pipeline (without UI):

    python rag_pipeline_from_scratch.py

Run the interactive Streamlit UI:

    streamlit run rag_pipeline_streamlit.py

Ensure required environment variables (e.g., OpenAI API key) are configured before running.

---

## ğŸ› ï¸ Technology Stack

- Python  
- LangGraph  
- LangChain  
- OpenAI LLMs  
- Embeddings  
- Vector Store  
- Streamlit  

---

## ğŸ“ˆ Learning Outcomes

This project demonstrates:

- How to build a **RAG pipeline using LangGraph**
- Differences between **graph-based workflows and linear chains**
- Clear separation of retrieval and generation steps
- Building both **CLI and UI-driven AI applications**
- Foundations for scaling toward agent-based RAG systems

---

## ğŸ”® Possible Enhancements

- Add conversational memory to the pipeline  
- Introduce conditional routing based on query complexity  
- Support multiple document formats (PDF, Markdown)  
- Add evaluation metrics for retrieval quality  
- Extend the graph with planner or summarizer nodes  

---

â­ This project serves as a **clean, foundational reference** for building **LangGraph-based RAG pipelines** with optional UI support.
