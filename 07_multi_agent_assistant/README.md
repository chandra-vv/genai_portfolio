# ğŸ§  LangGraph Multi-Agent Assistant

This project implements an advanced **Multi-Agent AI Assistant** using **LangGraph** and **LangChain**.  
It is designed to handle complex user queries by decomposing them into smaller tasks, retrieving relevant knowledge using embeddings and vector databases, and orchestrating execution through a graph-based workflow.

Unlike single-chain chatbots, this assistant follows an **agentic architecture** that supports planning, retrieval, memory, and intelligent routing. An interactive **Streamlit UI** allows users to experiment with the system and optionally query custom documents.

---

## ğŸ¯ Project Objectives

- Build a production-style multi-agent system using LangGraph
- Demonstrate query planning and task decomposition
- Implement Retrieval-Augmented Generation (RAG)
- Maintain conversation memory and context
- Provide an interactive UI for experimentation and learning

---

## âœ¨ Key Features

- ğŸ¤– Multi-Agent Architecture orchestrated using LangGraph  
- ğŸ§  Planner Agent to break complex queries into sub-questions  
- ğŸ” Retriever Agent powered by embeddings and FAISS  
- ğŸ›ï¸ Controller logic to route queries based on complexity  
- ğŸ’¾ Conversation memory for contextual continuity  
- ğŸ“„ Optional document upload for custom knowledge  
- ğŸ¨ Interactive Streamlit interface  
- âš¡ Powered by OpenAI GPT-3.5 Turbo  

---

## ğŸ§© System Architecture

The assistant is implemented as a **graph of nodes**, where each node has a clearly defined responsibility.

### Core Components

- **Planner Agent**  
  Decomposes complex user queries into smaller, focused sub-questions.

- **Retriever Agent**  
  Answers questions using embeddings and FAISS-based vector similarity search.

- **Controller (Graph Logic)**  
  Determines execution flow:
  - Complex queries â†’ Planner â†’ Retriever (loop) â†’ End  
  - Simple queries â†’ Retriever â†’ End  

- **Memory Node**  
  Stores and displays conversation context across turns.

---

## ğŸ”„ Execution Flow

1. User submits a query through the Streamlit UI  
2. Graph classifies the query as simple or complex  
3. Planner agent generates sub-questions (if required)  
4. Retriever agent answers using embeddings + FAISS  
5. LangGraph orchestrates execution and state updates  
6. Conversation memory is updated  
7. Final answers are displayed in the UI  

---

## ğŸ—‚ï¸ Project Structure

07_multi_agent_assistant/  
â”œâ”€â”€ agents/  
â”‚   â”œâ”€â”€ planner_agent.py        ## Generates sub-questions for complex queries  
â”‚   â””â”€â”€ retriever_agent.py      ## Retrieves answers using embeddings and FAISS  
â”‚  
â”œâ”€â”€ graph/  
â”‚   â””â”€â”€ langgraph_multi_agent.py  # LangGraph workflow and routing logic  
â”‚  
â”œâ”€â”€ about.txt                   # Sample knowledge base (replaceable)  
â”œâ”€â”€ app.py                      # Streamlit UI and entry point  
â”œâ”€â”€ requirements.txt            # Python dependencies  
â””â”€â”€ README.md                   # Project documentation  

---

## ğŸ“˜ Example

**Input Question**

How do embeddings improve Retrieval-Augmented Generation (RAG)?

**Generated Sub-Questions**
- What are embeddings?
- What is Retrieval-Augmented Generation?
- How do embeddings enable semantic search?

**Sample Output**
- Embeddings represent text as numerical vectors capturing semantic meaning.  
- In RAG systems, embeddings enable similarity-based retrieval of relevant documents.

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/chandra-vv/genai_portfolio.git  
cd genai_portfolio/07_multi_agent_assistant  
```
### 2ï¸âƒ£ Create and Activate Virtual Environment

```bash
python -m venv venv  
source venv/bin/activate      # macOS / Linux  
venv\\Scripts\\activate       # Windows  
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt  
```

### 4ï¸âƒ£ Configure Environment Variables

```bash
Create a `.env` file:

OPENAI_API_KEY=your_openai_api_key  
```

### 5ï¸âƒ£ Run the Application

```bash
streamlit run app.py  
```
---

## ğŸ› ï¸ Technology Stack

- Python  
- LangChain  
- LangGraph  
- OpenAI (GPT-3.5 Turbo)  
- FAISS (Vector Database)  
- Embeddings  
- Streamlit  
- python-dotenv  

---

## ğŸ“ˆ Learning Outcomes

This project demonstrates:
- Agent-based AI system design
- When to use planning vs direct retrieval
- How to orchestrate workflows using LangGraph
- How to combine RAG with memory
- How to build scalable and explainable GenAI systems

---

## ğŸ”® Future Enhancements

- Add a summarizer agent for long responses  
- Add scoring or ranking agents  
- Support PDF and CSV document ingestion  
- Improve memory using embedding-based recall  
- Enable parallel planning and retrieval  
- Deploy on Streamlit Cloud  

---

â­ This project serves as a reference implementation for building **agentic Generative AI systems** using LangGraph.
